{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AO84ljUU5Us"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JuhongPark/HairFastGAN/blob/app/app/MirrorMirrorGAN_Application.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Unh8nOjmFCgr"
      },
      "outputs": [],
      "source": [
        "# @title Model Load: Colab T4 GPU 기준 12분 가량 소요\n",
        "# Env Setting\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n",
        "!rm ninja-linux.zip\n",
        "!rm -rf sample_data\n",
        "\n",
        "!pip install diffusers==0.11.1\n",
        "!pip install transformers scipy ftfy accelerate\n",
        "!pip install jax==0.4.23 jaxlib==0.4.23\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "!pip install pillow==10.0.0 face_alignment dill==0.2.7.1 addict fpie git+https://github.com/openai/CLIP.git -q\n",
        "\n",
        "\n",
        "# Import\n",
        "from pathlib import Path\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from functools import cache\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from googletrans import Translator\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import requests\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import torchvision.transforms as T\n",
        "\n",
        "\n",
        "# Model load\n",
        "!git clone https://github.com/AIRI-Institute/HairFastGAN\n",
        "%cd HairFastGAN\n",
        "\n",
        "def install_packages():\n",
        "    !pip install pillow==10.0.0 face_alignment dill==0.2.7.1 addict fpie \\\n",
        "      git+https://github.com/openai/CLIP.git -q\n",
        "\n",
        "def download_models():\n",
        "    !git clone https://huggingface.co/AIRI-Institute/HairFastGAN\n",
        "    !cd HairFastGAN && git lfs pull && cd ..\n",
        "    !mv HairFastGAN/pretrained_models pretrained_models\n",
        "    !mv HairFastGAN/input input\n",
        "    !rm -rf HairFastGAN\n",
        "\n",
        "with ProcessPoolExecutor() as executor:\n",
        "    executor.submit(install_packages)\n",
        "    executor.submit(download_models)\n",
        "\n",
        "from hair_swap import HairFast, get_parser\n",
        "from models.Blending import Blending\n",
        "\n",
        "model_args = get_parser()\n",
        "hair_fast = HairFast(model_args.parse_args([]))\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "translator = Translator()\n",
        "\n",
        "\n",
        "################# Function #################\n",
        "%matplotlib inline\n",
        "\n",
        "def to_tuple(func):\n",
        "    def wrapper(arg):\n",
        "        if isinstance(arg, list):\n",
        "            arg = tuple(arg)\n",
        "        return func(arg)\n",
        "    return wrapper\n",
        "\n",
        "@to_tuple\n",
        "@cache\n",
        "def download_and_convert_to_pil(urls):\n",
        "    pil_images = []\n",
        "    for url in urls:\n",
        "        response = requests.get(url, allow_redirects=True, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "        pil_images.append(img)\n",
        "        print(f\"Downloaded an image of size {img.size}\")\n",
        "    return pil_images\n",
        "\n",
        "def display_images(images=None, **kwargs):\n",
        "    is_titles = images is None\n",
        "    images = images or kwargs\n",
        "\n",
        "    grid = gridspec.GridSpec(1, len(images))\n",
        "    fig = plt.figure(figsize=(20, 10))\n",
        "\n",
        "    for i, item in enumerate(images.items() if is_titles else images):\n",
        "        title, img = item if is_titles else (None, item)\n",
        "\n",
        "        img = T.functional.to_pil_image(img) if isinstance(img, torch.Tensor) else img\n",
        "        img = Image.open(img) if isinstance(img, str | Path) else img\n",
        "\n",
        "        ax = fig.add_subplot(1, len(images), i+1)\n",
        "        ax.imshow(img)\n",
        "        if title:\n",
        "            ax.set_title(title, fontsize=20)\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "is_any_url = False\n",
        "\n",
        "def try_download_image(url):\n",
        "    is_any_url = True\n",
        "    try:\n",
        "        return download_and_convert_to_pil([url])[0]\n",
        "    except Exception as e:\n",
        "        print(f\"Can't download the image from the link {url}\")\n",
        "        print(e)\n",
        "        return False\n",
        "\n",
        "def convert_input(inp):\n",
        "    if not inp.startswith('http'):\n",
        "        path = os.path.join(input_path, inp)\n",
        "        try:\n",
        "            if os.path.isfile(path):\n",
        "                path_to_imgs[path] = Image.open(path)\n",
        "                return path_to_imgs[path]\n",
        "        except Exception as e:\n",
        "            print(f\"Can't open the image {inp}\")\n",
        "            print(e)\n",
        "            return False\n",
        "    else:\n",
        "        return try_download_image(inp)\n",
        "\n",
        "if 'hair_fast_instans' not in globals():\n",
        "    if 'hair_fast' in globals():\n",
        "        hair_fast_instans = {'Default': hair_fast}\n",
        "    else:\n",
        "        model_args = get_parser()\n",
        "        hair_fast = HairFast(model_args.parse_args([]))\n",
        "        hair_fast_instans = {'Default': hair_fast}\n",
        "\n",
        "if 'path_to_imgs' not in globals():\n",
        "    path_to_imgs = {}\n",
        "\n",
        "Blending_checkpoint = \"Default\"\n",
        "Alignment_images = \"Auto\"\n",
        "Poisson_Blending = \"Off\"\n",
        "Poissons_iters = 115\n",
        "Poisson_erossion = 15\n",
        "\n",
        "if Blending_checkpoint not in hair_fast_instans:\n",
        "    if Blending_checkpoint == 'Alternative_v1':\n",
        "        new_args = model_args.parse_args(['--blending_checkpoint', 'pretrained_models/Blending/checkpoint_old.pth'])\n",
        "    elif Blending_checkpoint == 'Alternative_v2':\n",
        "        new_args = model_args.parse_args(['--blending_checkpoint', 'pretrained_models/Blending/checkpoint_old2.pth'])\n",
        "    else:\n",
        "        raise ValueError(f'{Blending_checkpoint} not exist')\n",
        "\n",
        "    hair_fast_ = copy(hair_fast)\n",
        "    hair_fast_.blend = Blending(new_args, net=hair_fast_.net)\n",
        "    hair_fast_instans[Blending_checkpoint] = hair_fast_\n",
        "\n",
        "def get_image_from_en(prompt_en, path='img'):\n",
        "    input_path = \"/content/HairFastGAN/input\"\n",
        "\n",
        "    image = pipe(prompt_en).images[0]\n",
        "\n",
        "    image.save(f\"{input_path}/{path}.png\")\n",
        "\n",
        "    return image\n",
        "\n",
        "def get_image_from_korean(style_kr, path='img'):\n",
        "    style_en = translator.translate(style_kr, src='ko', dest='en').text\n",
        "\n",
        "    prompt_en = f'A photograph of a person with a {style_en} hairstyle, featuring prominently styled hair, looking directly into the camera with a neutral expression, similar to a Korean passport photo. The face is centered and fully visible, with ample space above the head, ensuring no part of the hairstyle is cut off. The background is plain and neutral-colored.'\n",
        "\n",
        "    image = get_image_from_en(prompt_en, path)\n",
        "\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "XtlFO6RKjLOj",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# @title Hair Generative AI\n",
        "# @markdown Face 사진 업로드\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import io\n",
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "save_dir = '/content/HairFastGAN/input'\n",
        "\n",
        "# 파일 업로드 및 저장 함수 정의\n",
        "def upload_and_save(selected_name):\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for original_file_name in uploaded.keys():\n",
        "        print(f\"업로드된 {selected_name} 파일 이름: {original_file_name}\")\n",
        "        image = Image.open(io.BytesIO(uploaded[original_file_name]))\n",
        "        if image.mode != 'RGB' and image.mode != 'RGBA':\n",
        "            image = image.convert('RGB')\n",
        "        save_path = os.path.join(save_dir, f\"{selected_name}.png\")\n",
        "        image.save(save_path)\n",
        "        print('')\n",
        "        print('*' * 45)\n",
        "        print(f\"아래 이미지가 {selected_name} 이미지로 저장되었습니다.\")\n",
        "        display(image)\n",
        "\n",
        "# 버튼 클릭 시 호출되는 함수 정의\n",
        "def on_button_click(selected_name):\n",
        "    upload_and_save(selected_name)\n",
        "\n",
        "# 버튼 생성 및 클릭 이벤트 설정\n",
        "face_button = widgets.Button(description=\"Face 사진 업로드\")\n",
        "\n",
        "face_button.on_click(lambda b: on_button_click('Face'))\n",
        "\n",
        "# 버튼 표시\n",
        "display(face_button)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown Shape 사진 업로드\n",
        "# 버튼 생성 및 클릭 이벤트 설정\n",
        "shape_button = widgets.Button(description=\"Shape 사진 업로드\")\n",
        "\n",
        "shape_button.on_click(lambda b: on_button_click('Shape'))\n",
        "\n",
        "# 버튼 표시\n",
        "display(shape_button)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JO053PnuVgLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown Color 사진 업로드\n",
        "# 버튼 생성 및 클릭 이벤트 설정\n",
        "color_button = widgets.Button(description=\"Color 사진 업로드\")\n",
        "\n",
        "color_button.on_click(lambda b: on_button_click('Color'))\n",
        "\n",
        "# 버튼 표시\n",
        "display(color_button)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "bnP6JRLsVvDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1pXoM9lfdx2b"
      },
      "outputs": [],
      "source": [
        "# @markdown Hair 이미지 생성 - 옵션 메세지 입력 (미입력시, 위에서 업로드된 사진 사용)\n",
        "input_path = \"/content/HairFastGAN/input\"\n",
        "Face = \"Face.png\"\n",
        "\n",
        "Shape =  \"\"                           # @param {type:\"string\"}\n",
        "if Shape != \"\":\n",
        "    print(f'{Shape}의 Shape 이미지를 생성합니다.')\n",
        "    get_image_from_korean(Shape, 'Shape')\n",
        "Shape = \"Shape.png\"\n",
        "\n",
        "Color = \"\"                              # @param {type:\"string\"}\n",
        "if Color !=\"\":\n",
        "    print(f'{Color}의 Color 이미지를 생성합니다.')\n",
        "    get_image_from_korean(Color, 'Color')\n",
        "Color = \"Color.png\"\n",
        "\n",
        "\n",
        "converted_inputs = list(map(convert_input, (Face, Shape, Color)))\n",
        "need_alignment = any(map(lambda img: img.size != (1024, 1024), converted_inputs))\n",
        "\n",
        "if Alignment_images == 'On' or Alignment_images == 'Auto' and (need_alignment or is_any_url):\n",
        "    print('Hair 이미지 생성을 시작합니다.', file=sys.stderr)\n",
        "    result_image, *converted_inputs = hair_fast_instans[Blending_checkpoint](*converted_inputs, align=True)\n",
        "else:\n",
        "    result_image = hair_fast_instans[Blending_checkpoint](*converted_inputs)\n",
        "\n",
        "face_obj, shape_obj, color_obj = converted_inputs\n",
        "\n",
        "if Poisson_Blending == 'On':\n",
        "    print('Start poisson blending', file=sys.stderr)\n",
        "    result_image, _ = poisson_image_blending(result_image, face_obj, dilate_erosion=Poisson_erossion, maxn=Poissons_iters)\n",
        "\n",
        "print('Hair 이미지 생성을 완료했습니다.', file=sys.stderr)\n",
        "display_images(face=face_obj, shape=shape_obj, color=color_obj, result=result_image)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
